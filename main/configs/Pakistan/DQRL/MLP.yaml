
policy: "MLP"
algo: "MLP"

seed: 42

env:
  dataset: "Pakistan"
  flag: "Tuple30K"
  refresh_rate: 0.005

eval:
  lambda: [1, 0.1, 0.1]
  expected_max_latency: 210
  expected_max_energy: 800

training:
  num_epochs: 15
  batch_size: 1024
  lr: 0.005
  lr_decay: 0.95
  gamma: 0.02
  epsilon: 0.1
  epsilon_decay: 0.5
  reward_scale: 10000
  lambda: [1, 0.1, 0.05]

model:
  d_model: 64
  n_layers: 2
  # obs_type: ["cpu"]
  # obs_type: ["cpu", "buffer"]
  obs_type: ["cpu", "bw", "buffer"]
  bias: true

